<!doctype html><html class=min-height-full lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1,shrink-to-fit=no" name=viewport><meta content="light dark" name=color-scheme><link href=/favicon.ico rel=icon type=image/x-icon><link href=//fonts.gstatic.com/s/atkinsonhyperlegible/v10/9Bt23C1KxNDXMspQ1lPyU89-1h6ONRlW45G04pIo.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/feed.xml rel=alternate type=application/atom+xml title="Alex Saveau"><title>The need for new instructions: atomic bit fill and drain | Alex Saveau</title><meta content="Jekyll v4.3.2" name=generator><meta content="The need for new instructions: atomic bit fill and drain" property=og:title><meta content="Alex Saveau" name=author><meta content=en_US property=og:locale><meta content="In the previous article, I proposed a new lockless channel architecture based on two bit vectors. One is used to reserve access to a memory region, the other to commit changes. I showed promising theoretical performance improvements: whereas existing architectures pay the cost of linearizability without clients being able to take advantage of such consistency, lockless bags allow each element in the channel to be operated upon fully independently. In theory." name=description><meta content="In the previous article, I proposed a new lockless channel architecture based on two bit vectors. One is used to reserve access to a memory region, the other to commit changes. I showed promising theoretical performance improvements: whereas existing architectures pay the cost of linearizability without clients being able to take advantage of such consistency, lockless bags allow each element in the channel to be operated upon fully independently. In theory." property=og:description><link href=https://alexsaveau.dev/blog/opinions/performance/lockness/atomic-bit-fill rel=canonical><meta content=https://alexsaveau.dev/blog/opinions/performance/lockness/atomic-bit-fill property=og:url><meta content="Alex Saveau" property=og:site_name><meta content=https://alexsaveau.dev/assets/resized/me2-800-min.jpg property=og:image><meta content=article property=og:type><meta content=2025-09-24T00:00:00+00:00 property=article:published_time><meta content=summary_large_image name=twitter:card><meta content=https://alexsaveau.dev/assets/resized/me2-800-min.jpg property=twitter:image><meta content="The need for new instructions: atomic bit fill and drain" property=twitter:title><meta content=@SUPERCILEX name=twitter:site><meta content=@SUPERCILEX name=twitter:creator><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alex Saveau"},"dateModified":"2025-09-25T00:58:09+00:00","datePublished":"2025-09-24T00:00:00+00:00","description":"In the previous article, I proposed a new lockless channel architecture based on two bit vectors. One is used to reserve access to a memory region, the other to commit changes. I showed promising theoretical performance improvements: whereas existing architectures pay the cost of linearizability without clients being able to take advantage of such consistency, lockless bags allow each element in the channel to be operated upon fully independently. In theory.","headline":"The need for new instructions: atomic bit fill and drain","image":"https://alexsaveau.dev/assets/resized/me2-800-min.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://alexsaveau.dev/blog/opinions/performance/lockness/atomic-bit-fill"},"url":"https://alexsaveau.dev/blog/opinions/performance/lockness/atomic-bit-fill"}</script><script>window.addEventListener("DOMContentLoaded",()=>{for(let e of document.querySelectorAll(".loads")){var o=()=>{e.classList.remove("loads")};e.complete?o():(e.onload=o,e.onerror=o)}})</script><noscript><style>.loads{animation:none!important;background-color:unset!important}</style></noscript><link href=//fonts.gstatic.com/s/firacode/v17/uU9NCBsR6Z2vfE9aq3bh3dSD.woff2 rel=preload type=font/woff2 as=font crossorigin><style>@keyframes tooltip-appear{0%{opacity:0}to{opacity:1}}@keyframes pulse{0%,to{opacity:1}50%{opacity:.33}}:root{--progress-color:gray;--blockquote-color:#6a737d;--blockquote-boarder-color:#959da5;--code-background-color:rgba(0, 0, 0, 0.05);--hr-color:gray;--footer-color:white;--loading-pulse-color:#b0b0b0}@font-face{font-family:"Fira Code";font-style:normal;font-weight:475;font-display:swap;src:url(//fonts.gstatic.com/s/firacode/v17/uU9NCBsR6Z2vfE9aq3bh3dSD.woff2) format("woff2");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}.article{overflow-wrap:break-word}.article .highlight{background-color:rgba(0,0,0,.04);border-radius:3px}.article h2{margin:1.5em 0-.5em;font-size:1.875rem}.article h2 code{font-size:1.625rem}.article p{font-size:1.313rem;margin:.95em 0 1.2em}.article strong{font-size:1.25rem}.article code{font-family:"Fira Code",monospace;font-size:1rem;background-color:var(--code-background-color);border-radius:3px;padding:2px 4px}.article div pre{padding:20px}.article div pre code,a{background-color:transparent}.article div pre code{padding:0}.article li ul,.article ol,.article ul{font-size:1.313rem;padding-left:32px;margin-bottom:16px}.article li ul{padding-left:16px;margin-bottom:0}.header-link{visibility:hidden}h2:hover .header-link{visibility:visible}.octicon{display:inline-block;fill:currentColor;vertical-align:text-bottom}html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji";line-height:1.5;color:#24292e;background-color:#fff;font-family:Atkinson Hyperlegible,sans-serif;font-size:1em}footer{display:block;display:flex;padding:5px;align-items:center;background-color:var(--footer-color)}a{color:#0366d6;text-decoration:none}a:active,a:hover{outline-width:0}strong{font-weight:600}h1{margin:.67em 0}small{font-size:90%}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}*{box-sizing:border-box}a:hover{text-decoration:underline}h1,h2,ol,p,pre,ul{margin-top:0;margin-bottom:0}h1,h2{font-size:2rem;font-weight:600}h2{font-size:1.5rem}p{margin-bottom:10px}ol,ul{padding-left:0}code,pre{font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,monospace;font-size:.75rem}:-ms-input-placeholder{color:#6a737d;opacity:1}::-ms-input-placeholder{color:#6a737d;opacity:1}:checked+.radio-label{position:relative;z-index:1;border-color:#0366d6}@media (min-width:768px){.col-md-5{width:41.66667%}.col-md-7{width:58.33333%}}@media (min-width:1012px){.col-lg-4{width:33.33333%}.col-lg-8{width:66.66667%}}@media (min-width:1280px){.col-xl-3{width:25%}.col-xl-9{width:75%}}.tooltipped{position:relative}.tooltipped::after,.tooltipped::before{position:absolute;display:none;pointer-events:none;opacity:0}.tooltipped::after{z-index:1000000;padding:.5em .75em;font:11px/1.5 -apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji";-webkit-font-smoothing:subpixel-antialiased;color:#fff;text-align:center;text-decoration:none;text-shadow:none;text-transform:none;letter-spacing:normal;word-wrap:break-word;white-space:pre;content:attr(aria-label);background:#1b1f23;border-radius:6px}.tooltipped::before{z-index:1000001;width:0;height:0;color:#1b1f23;content:"";border:6px solid transparent}.tooltipped:active::after,.tooltipped:active::before,.tooltipped:focus::after,.tooltipped:focus::before,.tooltipped:hover::after,.tooltipped:hover::before{display:inline-block;text-decoration:none;animation-name:tooltip-appear;animation-duration:.1s;animation-fill-mode:forwards;animation-timing-function:ease-in;animation-delay:.4s}.tooltipped-se::after{top:100%;margin-top:6px}.tooltipped-se::before{top:auto;right:50%;bottom:-7px;margin-right:-6px;border-bottom-color:#1b1f23}.tooltipped-se::after{right:auto;left:50%;margin-left:-16px}.border-top{border-top:1px solid #e1e4e8!important}@media (min-width:768px){.border-md-right{border-right:1px solid #e1e4e8!important}.border-md-bottom{border-bottom:1px solid #e1e4e8!important}.border-md-top-0{border-top:0!important}}.circle{border-radius:50%!important}.border-gray-light{border-color:#eaecef!important}.bg-white{background-color:#fff!important}.bg-gray-light{background-color:#fafbfc!important}.text-gray{color:#586069!important}.flex-wrap{flex-wrap:wrap!important}.flex-items-start{align-items:flex-start!important}.flex-items-center{align-items:center!important}.flex-self-stretch{align-self:stretch!important}.v-align-middle{vertical-align:middle!important}.mr-2{margin-right:8px!important}.mx-auto{margin-right:auto!important;margin-left:auto!important}.px-4{padding-right:24px!important;padding-left:24px!important}.f4{font-size:1rem!important}@media (min-width:768px){.px-md-6{padding-right:40px!important;padding-left:40px!important}.f4{font-size:1rem!important}}.f5{font-size:.875rem!important}.f00-light{font-size:2.5rem!important;font-weight:300!important}@media (min-width:768px){.f00-light{font-size:3rem!important}}.f2-light{font-size:1.375rem!important;font-weight:300!important}.lh-condensed{line-height:1.25!important}.d-flex{display:flex!important}.d-none{display:none!important}@font-face{font-family:Inter;font-style:normal;font-weight:400;src:local("Inter"),local("Inter-Regular"),url(/fonts/Inter-Regular.woff) format("woff");font-display:swap}@font-face{font-family:Inter;font-style:normal;font-weight:500;src:local("Inter Medium"),local("Inter-Medium"),url(/fonts/Inter-Medium.woff) format("woff");font-display:swap}@font-face{font-family:Inter;font-style:normal;font-weight:600;src:local("Inter Bold"),local("Inter-Bold"),url(/fonts/Inter-Bold.woff) format("woff");font-display:swap}.mb-2{margin-bottom:8px!important}.mb-3{margin-bottom:16px!important}.mb-5{margin-bottom:32px!important}.mb-6{margin-bottom:40px!important}.py-6{padding-top:40px!important;padding-bottom:40px!important}.highlight{width:100%;overflow:auto;background:#fff}@font-face{font-family:"Atkinson Hyperlegible";font-style:normal;font-weight:400;font-display:swap;src:url(//fonts.gstatic.com/s/atkinsonhyperlegible/v10/9Bt23C1KxNDXMspQ1lPyU89-1h6ONRlW45G04pIo.woff2) format("woff2");unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}footer small{width:100%}footer small:last-child{text-align:end}.min-height-full{min-height:100vh}.icon-color{fill:#24292e!important}.loads{animation-duration:2s;animation:2s cubic-bezier(.4,0,.6,1) infinite pulse;animation-timing-function:cubic-bezier(.4,0,.6,1);animation-iteration-count:infinite;animation-name:pulse;background-color:var(--loading-pulse-color)}@media (min-width:768px){.f2-light{font-size:1.5rem!important}.d-md-flex{display:flex!important}#masthead{position:fixed;width:min-content}.masthead-name-mobile{display:none}}@media (max-width:768px){.masthead-mini{padding-top:10px!important;padding-bottom:10px!important}.masthead-mini-container{display:flex;align-items:center}.masthead-profile{width:80px;height:80px;margin-bottom:0!important}.masthead-intro{padding-left:24px}.masthead-name{display:none}.masthead-bio{margin-bottom:0!important}.masthead-metadata{display:none}}@media (min-width:1942px){.masthead{max-width:400px}.content-container{width:100%}}@media (prefers-color-scheme:dark){:root{--progress-color:whitesmoke;--blockquote-color:#dadada;--blockquote-boarder-color:#dadada;--code-background-color:rgba(255,255,255,0.15);--hr-color:whitesmoke;--footer-color:black;--loading-pulse-color:#383838}.article p{color:#ededed}.highlight pre{background-color:#272822}a{color:unset!important;text-decoration:underline}.bg-white{background-color:#4f565d!important}.bg-gray-light{background-color:#2f363d!important}.border-gray-light{border-color:transparent!important}.text-gray{color:#d0d8e1!important}.border-md-bottom{border:0!important}.masthead{background-color:#24292e!important}.scoped-text-defaults,.text-defaults,.text-defaults *{color:#fff!important}.icon-color{fill:#fff!important}}</style><body class=min-height-full id=top><div class="min-height-full bg-gray-light border-md-bottom d-md-flex"><div class="px-4 px-lg-7 py-6 bg-white border-gray-light border-md-right col-lg-4 col-md-5 col-xl-3 flex-self-stretch masthead masthead-mini px-md-6"><div class=masthead-mini-container id=masthead><a href=/ ><picture><source sizes=150px srcset="/assets/resized/me2-240-min.avif 240w, /assets/resized/me2-320-min.avif 320w, /assets/resized/me2-480-min.avif 480w, /assets/resized/me2-800-min.avif 800w, /assets/resized/me2-min.avif 1528w" type=image/avif><source sizes=150px srcset="/assets/resized/me2-240-min.webp 240w, /assets/resized/me2-320-min.webp 320w, /assets/resized/me2-480-min.webp 480w, /assets/resized/me2-800-min.webp 800w, /assets/resized/me2-min.webp 1528w" type=image/webp><source sizes=150px srcset="/assets/resized/me2-240-min.jpg 240w, /assets/resized/me2-320-min.jpg 320w, /assets/resized/me2-480-min.jpg 480w, /assets/resized/me2-800-min.jpg 800w, /assets/resized/me2-min.jpg 1528w" type=image/jpeg><source sizes=150px srcset="/assets/resized/me2-240.jpg 240w, /assets/resized/me2-320.jpg 320w, /assets/resized/me2-480.jpg 480w, /assets/resized/me2-800.jpg 800w, /assets/me2.jpg 1528w"><img alt="Profile Picture" class="mb-3 circle loads masthead-profile" height=150 loading=lazy src=/assets/resized/me2-240.jpg width=150></picture></a><div class=masthead-intro><h1 class="text-defaults lh-condensed mb-2 masthead-name">Alex Saveau</h1><h2 class="text-defaults lh-condensed mb-2 masthead-name-mobile">Alex Saveau</h2><p class="mb-3 f4 masthead-bio text-gray" id=bio>Relentless efficiency</div><div class="f4 masthead-metadata"><div class="text-defaults d-flex flex-items-center mb-3"><svg height=20 viewBox="0 0 16 16" aria-label=GitHub class="icon-color mr-2 octicon v-align-middle octicon-mark-github" role=img version=1.1 width=20><path d="M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"></path></svg> <a href=//github.com/SUPERCILEX>@SUPERCILEX</a></div><div class="text-defaults d-flex flex-items-center mb-3"><svg height=20 viewBox="0 0 16 16" aria-label=email class="icon-color mr-2 octicon v-align-middle octicon-mail" role=img version=1.1 width=20><path d="M1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25v-8.5C0 2.784.784 2 1.75 2ZM1.5 12.251c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V5.809L8.38 9.397a.75.75 0 0 1-.76 0L1.5 5.809v6.442Zm13-8.181v-.32a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25v.32L8 7.88Z"></path></svg> <a href=mailto:saveau.alexandre@gmail.com>saveau.alexandre@gmail.com</a></div><div class="flex-items-start d-flex flex-wrap"><div class=mb-3><a href=//stackoverflow.com/u/4548500 class="tooltipped tooltipped-se" aria-label="Stack Overflow: 4548500"><svg height=24 viewBox="0 0 120 120" fill=#959da5 xmlns=http://www.w3.org/2000/svg><path d="M84.4 93.8V70.6h7.7v30.9H22.6V70.6h7.7v23.2z" class=st0 /><path d="M38.8 68.4l37.8 7.9 1.6-7.6-37.8-7.9-1.6 7.6zm5-18l35 16.3 3.2-7-35-16.4-3.2 7.1zm9.7-17.2l29.7 24.7 4.9-5.9-29.7-24.7-4.9 5.9zm19.2-18.3l-6.2 4.6 23 31 6.2-4.6-23-31zM38 86h38.6v-7.7H38V86z" class=st1 /></svg><span class=d-none>Stack Overflow</span></a></div></div></div></div></div><div class="px-4 px-lg-7 py-6 border-md-top-0 border-top col-lg-8 col-md-7 col-xl-9 content-container" id=article><div class=mx-auto style=max-width:900px><div class="f4 mb-6"><div class="f4 scoped-text-defaults"><p class=f5><a href=/blog class="text-defaults d-flex flex-items-center"><svg height=16 viewBox="0 0 16 16" aria-label=include.parent class="icon-color mr-2 octicon v-align-middle octicon-chevron-left" role=img version=1.1 width=16><path d="M9.78 12.78a.75.75 0 0 1-1.06 0L4.47 8.53a.75.75 0 0 1 0-1.06l4.25-4.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L6.06 8l3.72 3.72a.75.75 0 0 1 0 1.06Z"></path></svg>Blog</a><h1 class="text-defaults lh-condensed f00-light" style=font-weight:600!important>The need for new instructions: atomic bit fill and drain</h1><h2 class="lh-condensed f2-light text-gray" style=font-weight:400!important>Hardware acceleration for lockless channels</h2><p class="mb-5 text-gray">Published Sep 24, 2025 • Last updated Sep 25, 2025 • 5 min read<div class=article><p>In the <a href=lockless-queues-are-not-queues>previous article</a>, I proposed a new lockless channel architecture based on two bit vectors. One is used to reserve access to a memory region, the other to commit changes. I showed promising theoretical performance improvements: whereas existing architectures pay the cost of linearizability without clients being able to take advantage of such consistency, lockless bags allow each element in the channel to be operated upon fully independently. In theory.<p>In practice, hardware processes atomic operations by locking cache lines. Readers and writers in lockless bags need to modify both bit vectors, which means locking both cache lines and neutering any performance benefits offered by lockless bags. How can we fix this?<p>Hardware needs to give software an efficient mechanism for locking memory regions.<h2 id=new-instructions-atomic_bit_filldrain-and-atomic_bit_set>New instructions: <code class="highlighter-rouge language-plaintext">atomic_bit_{fill,drain}</code> and <code class="highlighter-rouge language-plaintext">atomic_bit_set</code> <a href=#new-instructions-atomic_bit_filldrain-and-atomic_bit_set class=header-link>#</a></h2><p>Here are the proposed signatures:<div class="highlighter-rouge language-plaintext"><div class=highlight><pre class=highlight><code>atomic_bit_{fill,drain}: {cache line address, max # bits} => {changed bit mask}
atomic_bit_set: {cache line address, bit mask} => {}
</code></pre></div></div><p>Given a cache line and a maximum number of bits <em>M</em> to fill, <code class="highlighter-rouge language-plaintext">atomic_bit_fill</code> scans the cache line for zeros and flips at most <em>M</em> of them to ones. It returns the mask of flipped bits. <code class="highlighter-rouge language-plaintext">atomic_bit_drain</code> operates identically except that it scans for ones and returns them to zero. These instructions could operate on machine words, but the more bits you have the deeper your channel queue can be. I assume it wouldn’t be too difficult to return 512-bit change masks and use AVX-512 instructions to compute indices out of the mask.<h2 id=how-do-you-use-these-instructions>How do you use these instructions? <a href=#how-do-you-use-these-instructions class=header-link>#</a></h2><p>The concepts from lockless bags apply mechanically:<ol><li>To prepare <em>M</em> elements, call <code class="highlighter-rouge language-plaintext">atomic_bit_fill</code> on the reservation bit vector.<li>Use the returned mask to write your elements into their corresponding array slots. An empty mask means the channel is full.<li>Once the elements have been written, call <code class="highlighter-rouge language-plaintext">atomic_bit_set</code> to update the commit bit vector.</ol><p>Receive elements by using <code class="highlighter-rouge language-plaintext">atomic_bit_drain</code> instead.<h2 id=why-are-these-instructions-more-powerful-than-existing-atomics>Why are these instructions more powerful than existing atomics? <a href=#why-are-these-instructions-more-powerful-than-existing-atomics class=header-link>#</a></h2><p><code class="highlighter-rouge language-plaintext">atomic_bit_{fill,drain}</code> offer novel acceleration opportunities: the key idea is that <strong>cores may issue requests without knowing the state of the bit vectors</strong>. This bears repeating: <code class="highlighter-rouge language-plaintext">cmpxchg</code> and atomic bitwise instructions require knowing the state of the word being operated upon prior to modification. On the other hand, <code class="highlighter-rouge language-plaintext">atomic_bit_{fill,drain}</code> instructions do not need to know the state of the word and therefore do not need to own the memory being operated upon, meaning <strong>cores can issue fill/drain requests in parallel</strong>.<p>Put another way, cores never need to pull the cache lines down. A synchronization point to process incoming requests remains, but in the time it takes the on-chip network to return the resulting bit mask to the originating core, other requests may have been issued and serviced, changing the state of our bit vector.<p>We’ve found a way to let cores communicate their ownership over memory regions concurrently! Global linearizability has been vanquished at last: operations over a particular element in the bit vectors are linearized, but each element’s operations are fully independent.<p>That’s not all! We have a poor man’s <a href=//dl.acm.org/doi/pdf/10.1145/3695053.3731026>Intel Dynamic Load Balancer</a>, but that doesn’t mean we can’t get a little fancy:<ul><li>The L1 data pre-fetcher could intelligently start loading the corresponding cache lines of the array slots we claimed when executing an <code class="highlighter-rouge language-plaintext">atomic_bit_{fill,drain}</code> instruction.<li>The CPU could move the bit vector cache lines around dynamically based on load. For example the lines could be in L3 if most cores are using it, or moved into the L2 of a core near the main sources of request traffic.<ul><li>Taking this idea further, the 512 bits could be dynamically partitioned by the CPU to local core complexes. Say your chip is organized such that groups of cores have faster means of communication amongst themselves than going to L3. Each group could get ownership over a slice of the 512 bits and fall back to asking other groups for bits only if the local partition is full/empty. Perhaps more interesting is partitioning across NUMA nodes.</ul><li>Cores could develop affinities/flows on a best effort basis. Say core A is frequently publishing data while another core B is frequently consuming data. The server handling fill/drain requests could learn this pattern and try to ensure B gets masks primarily containing A’s data to potentially improve locality.</ul><h2 id=the-nitty-gritty>The nitty-gritty <a href=#the-nitty-gritty class=header-link>#</a></h2><p>The instruction signatures I proposed above aren’t quite enough for a fully featured MPMC channel.<p>To implement sleeping on an empty or full channel, hardware support is required (unless the fill/drain instructions are implemented on 32-bit words). A sleeping bit will need to be reserved somewhere in the cache line. The <code class="highlighter-rouge language-plaintext">atomic_bit_set</code> instruction will need to support setting the sleeping bit atomically with the changed mask and return the previous state of the sleeping bit.<p>The fill/drain instructions also need to return a dead bit so channel disconnects can be handled properly.<p>Both of these bits can be placed at the end of the cache line and normal atomic bitwise operations need to be supported on the last 32 bits of the cache line so these bits can be updated as needed and used as a futex.<p>Additionally, the <code class="highlighter-rouge language-plaintext">atomic_bit_set</code> instruction doesn’t make sense as is: set the bits to what? So there could be two variants of the instruction, one to set the mask bits to zero and another to set them to one. Or the instruction could be expressed in terms of OR and AND operations, where the change mask is inverted when passed into the AND variant of the change mask update instruction.<p>Finally, <code class="highlighter-rouge language-plaintext">atomic_bit_set</code> should support acquire/release memory orderings.<h2 id=mpsc-channel-support>MPSC channel support <a href=#mpsc-channel-support class=header-link>#</a></h2><p>To support MPSC channels, additional hardware support is required. I couldn’t figure out a good way to maintain independence between <a href=lockless-queues-are-not-queues#mpsc-queues-are-special>streams</a>, so we return to global linearizability by implementing software lockless queues in hardware. The hardware can reserve some bits to represent head/tail pointers in each bit vector’s cache line, marking where the next bits should be filled/drained. The <code class="highlighter-rouge language-plaintext">atomic_bit_drain</code> instruction would only be allowed to return a non-empty mask when the head points to filled bits. Note that this approach incurs the same problems as described in <a href=lockless-queues-are-not-queues#lockless-queues-are-slow>the previous article</a> around unfortunately timed context switches blocking the entire channel.<p>However, hardware acceleration maintains the advantage of supporting concurrent requests to add elements to the channel.<h2 id=recap>Recap <a href=#recap class=header-link>#</a></h2><p>Existing lockless channels can only operate as fast as the hardware can move a cache line between cores, which can be <a href=//chipsandcheese.com/p/core-to-core-latency-data-on-large-systems>terribly slow</a>. This novel approach proposes a stateless hardware acceleration method for lockness channels: with it, cores can independently and concurrently request modification to the lockless channel. In essence, the new approach deeply pipelines updates while existing channels serialize updates.<p>Please reach out if you’re building something like this, I’d be very interested in providing the software implementation.</div></div></div></div></div></div><footer class=text-defaults><small>Copyright © 2018-2025 Alex Saveau</small> <small><a href=//github.com/SUPERCILEX/personal-website>Source</a> | <a href=//twitter.com/SUPERCILEX>Twitter</a> | <a href=#top>Back to top</a></small></footer>